import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
import mlflow
import mlflow.sklearn
import streamlit as st
import plotly.express as px
from sklearn.metrics import mean_squared_error, r2_score
import os

class TitanicAnalyzer:
    def __init__(self):
        self.data = None
        self.model = None
        self.scaler = None  # Sáº½ khá»Ÿi táº¡o sau khi cÃ³ dá»¯ liá»‡u
        self.poly = None
        self.feature_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
        self.is_fitted = False
    
    def load_and_preprocess(self, data_path):
        """Äá»c vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u vá»›i MLflow"""
        try:
            mlflow.start_run()
            st.write("**ðŸŸ¢ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u**")
            
            # Äá»c dá»¯ liá»‡u
            st.write("**1. Äá»c dá»¯ liá»‡u tá»« file CSV**")
            self.data = pd.read_csv(data_path)
            mlflow.log_param("initial_data_shape", self.data.shape)
            st.write("Dá»¯ liá»‡u ban Ä‘áº§u:", self.data.head())
            
            # Xá»­ lÃ½ missing values
            st.write("**2. Xá»­ lÃ½ giÃ¡ trá»‹ bá»‹ thiáº¿u báº±ng phÆ°Æ¡ng phÃ¡p trung bÃ¬nh**")
            st.write("\n- Äiá»n giÃ¡ trá»‹ thiáº¿u trong 'Age' báº±ng giÃ¡ trá»‹ trung bÃ¬nh.\n- Äiá»n giÃ¡ trá»‹ thiáº¿u trong 'Embarked' báº±ng giÃ¡ trá»‹ xuáº¥t hiá»‡n nhiá»u nháº¥t.")
            missing_values_before = self.data.isnull().sum().sum()
            st.write("Sá»‘ lÆ°á»£ng dá»¯ liá»‡u bá»‹ thiáº¿u : ")
            st.write(self.data.isnull().sum().T)
            imputer = SimpleImputer(strategy='mean')
            self.data[self.feature_columns] = imputer.fit_transform(self.data[self.feature_columns])
            missing_values_after = self.data.isnull().sum().sum()
            mlflow.log_metric("missing_values_before", missing_values_before)
            mlflow.log_metric("missing_values_after", missing_values_after)
            st.write("Dá»¯ liá»‡u sau khi xá»­ lÃ½ :", self.data.head())

            # XÃ³a cÃ¡c cá»™t khÃ´ng cáº§n thiáº¿t
            st.write("**3. XÃ³a cÃ¡c cá»™t khÃ´ng cáº§n thiáº¿t: Cabin, Name, Ticket**")
            st.write("\n- XÃ³a cá»™t 'Name' (TÃªn hÃ nh khÃ¡ch khÃ´ng áº£nh hÆ°á»›ng trá»±c tiáº¿p Ä‘áº¿n sá»‘ng sÃ³t hay khÃ´ng).\n- XÃ³a cá»™t 'Ticket' (Sá»‘ vÃ© lÃ  má»™t chuá»—i kÃ½ tá»± khÃ´ng mang nhiá»u Ã½ nghÄ©a rÃµ rÃ ng Ä‘á»‘i vá»›i mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n).\n- XÃ³a cá»™t 'Cabin' (Dá»¯ liá»‡u bá»‹ thiáº¿u quÃ¡ nhiá»u ,ráº¥t nhiá»u hÃ nh khÃ¡ch khÃ´ng cÃ³ thÃ´ng tin vá» cabin).")
            self.data.drop(columns=['Cabin', 'Name', 'Ticket'], inplace=True, errors='ignore')
            mlflow.log_param("after_column_removal_shape", self.data.shape)
            st.write("Dá»¯ liá»‡u sau khi xÃ³a cá»™t:", self.data.head())
            
            # Chuyá»ƒn Ä‘á»•i biáº¿n categorical
            st.write("**4. Chuyá»ƒn Ä‘á»•i biáº¿n phÃ¢n loáº¡i**")
            self.data['Sex'] = (self.data['Sex'] == 'female').astype(int)
            self.feature_columns.append('Sex')
            st.write("Dá»¯ liá»‡u sau khi chuyá»ƒn Ä‘á»•i 'Sex':", self.data[['Sex']].head())
            
            # One-hot encoding cho Embarked
            st.write("**5. One-hot encoding**")
            embarked_dummies = pd.get_dummies(self.data['Embarked'], prefix='Embarked')
            self.data = pd.concat([self.data, embarked_dummies], axis=1)
            self.feature_columns.extend(embarked_dummies.columns)
            mlflow.log_param("one_hot_encoded_columns", list(embarked_dummies.columns))
            st.write("Dá»¯ liá»‡u sau khi one-hot encoding:", self.data.head())
            
            mlflow.end_run()
            return self.data
            
        except Exception as e:
            st.error(f"Lá»—i khi tiá»n xá»­ lÃ½ dá»¯ liá»‡u: {str(e)}")
            mlflow.end_run(status='FAILED')
            return None

    def split_data(self, train_size=0.7, valid_size=0.15):
        """Chia dá»¯ liá»‡u thÃ nh táº­p train/valid/test vÃ  chuáº©n hÃ³a"""
        try:
            with mlflow.start_run(run_name="Data_Splitting"):
                
                st.write("**ðŸŸ¢ Chia dá»¯ liá»‡u thÃ nh táº­p train/valid/test**")
                
                test_size = 1 - train_size - valid_size
                st.write(f"ðŸ”¸ Tá»‰ lá»‡: Train = {train_size}, Valid = {valid_size}, Test = {test_size}")
                
                X = self.data[self.feature_columns]
                y = self.data['Survived']
                
                # Split thÃ nh train vÃ  temp
                st.write("**1. Chia dá»¯ liá»‡u thÃ nh táº­p train vÃ  táº­p táº¡m thá»i**")
                X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train_size, random_state=42)
                st.write(f"ðŸ”¹ KÃ­ch thÆ°á»›c táº­p train: {X_train.shape}")
                
                # Split temp thÃ nh valid vÃ  test
                valid_ratio = valid_size / (valid_size + test_size)
                st.write("**2. Chia táº­p táº¡m thá»i thÃ nh táº­p validation vÃ  test**")
                X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, train_size=valid_ratio, random_state=42)
                st.write(f"ðŸ”¸ KÃ­ch thÆ°á»›c táº­p valid: {X_valid.shape}")
                st.write(f"ðŸ”¸ KÃ­ch thÆ°á»›c táº­p test: {X_test.shape}")
                
                # Khá»Ÿi táº¡o vÃ  fit scaler vá»›i training data
                st.write("**3. Chuáº©n hÃ³a dá»¯ liá»‡u báº±ng StandardScaler**")
                self.scaler = StandardScaler()
                X_train_scaled = self.scaler.fit_transform(X_train)
                X_valid_scaled = self.scaler.transform(X_valid)
                X_test_scaled = self.scaler.transform(X_test)
                
                st.write("ðŸ“Š **Dá»¯ liá»‡u sau khi chuáº©n hÃ³a (5 dÃ²ng Ä‘áº§u tiÃªn):**")
                st.write(pd.DataFrame(X_train_scaled[:5], columns=self.feature_columns))
                
                self.is_fitted = True
                
                # Log thÃ´ng tin vÃ o MLflow
                mlflow.log_param("train_size", X_train.shape)
                mlflow.log_param("valid_size", X_valid.shape)
                mlflow.log_param("test_size", X_test.shape)
                mlflow.log_param("scaling_method", "StandardScaler")
                mlflow.end_run()
                
                return (X_train_scaled, X_valid_scaled, X_test_scaled, y_train, y_valid, y_test)
                        
        except Exception as e:
            mlflow.log_param("status", "FAILED")
            st.error(f"âŒ Lá»—i khi chia dá»¯ liá»‡u: {str(e)}")
            mlflow.end_run(status='FAILED')
            return None

    def predict_survival(self, input_data):
        """Dá»± Ä‘oÃ¡n cho dá»¯ liá»‡u má»›i"""
        try:
            if not self.is_fitted:
                raise Exception("Model is not fitted yet. Please train the model first.")
            
            # Scale input using fitted scaler
            input_scaled = self.scaler.transform(input_data[self.feature_columns])
            
            # Predict
            if self.poly is not None:
                input_poly = self.poly.transform(input_scaled)
                prediction = self.model.predict(input_poly)[0]
            else:
                prediction = self.model.predict(input_scaled)[0]
            
            return prediction
            
        except Exception as e:
            st.error(f"Error in prediction: {str(e)}")
            return None

def create_streamlit_app():
    st.title("Titanic Survival Analysis")
    
    # Sá»­ dá»¥ng st.tabs Ä‘á»ƒ táº¡o thanh menu
    tab2, tab3 = st.tabs([ "ðŸ” Huáº¥n luyá»‡n vÃ  Dá»± Ä‘oÃ¡n", "ðŸš€ MLflow"])
    analyzer = TitanicAnalyzer()
        
    with tab2:
            st.header("Dá»± Ä‘oÃ¡n kháº£ nÄƒng sá»‘ng sÃ³t trÃªn tÃ u Titanic")

            data_path = "G:/ML/MLFlow/my_env/titanic.csv"  # ÄÆ°á»ng dáº«n cá»‘ Ä‘á»‹nh
            analyzer = TitanicAnalyzer()
            data = analyzer.load_and_preprocess(data_path)
                    
            # Parameters
            st.sidebar.header("Training Parameters")
            train_size = st.sidebar.slider("Training Set Size", 0.5, 0.8, 0.7)
            valid_size = st.sidebar.slider("Validation Set Size", 0.1, 0.25, 0.15)
            degree = st.sidebar.selectbox("Polynomial Degree", [1, 2, 3])
            
            st.write("Train Model")
                # Split data
            splits = analyzer.split_data(train_size, valid_size)
                
            if splits is not None:
                X_train, X_valid, X_test, y_train, y_valid, y_test = splits
                
                with mlflow.start_run():
                    # Train model
                    if degree > 1:
                        analyzer.poly = PolynomialFeatures(degree=degree)
                        X_train_poly = analyzer.poly.fit_transform(X_train)
                        X_valid_poly = analyzer.poly.transform(X_valid)
                        X_test_poly = analyzer.poly.transform(X_test)
                        
                        analyzer.model = LogisticRegression()
                        analyzer.model.fit(X_train_poly, y_train)
                        # Dá»± Ä‘oÃ¡n
                        y_pred_train = analyzer.model.predict(X_train_poly)
                        y_pred_valid = analyzer.model.predict(X_valid_poly)
                        y_pred_test = analyzer.model.predict(X_test_poly)
                    else:
                        analyzer.model = LogisticRegression()
                        analyzer.model.fit(X_train, y_train)
                    
                    # Luwu mÃ´ hÃ¬nh vÃ o session_state
                        st.session_state['model'] = analyzer.model
                        st.session_state['scaler'] = analyzer.scaler
                        st.session_state['poly'] = analyzer.poly
                    # Dá»± Ä‘oÃ¡n
                        y_pred_train = analyzer.model.predict(X_train)
                        y_pred_valid = analyzer.model.predict(X_valid)
                        y_pred_test = analyzer.model.predict(X_test)
                    
                    # Calculate metrics
                    
                    mse_train = mean_squared_error(y_train, y_pred_train)
                    r2_train = r2_score(y_train, y_pred_train)
                    mse_valid = mean_squared_error(y_valid, y_pred_valid)
                    r2_valid = r2_score(y_valid, y_pred_valid)
                    mse_test = mean_squared_error(y_test, y_pred_test)
                    r2_test = r2_score(y_test, y_pred_test)
                    
                    # Cross-validation
                    y_pred_cv = cross_val_predict(analyzer.model, X_train, y_train, cv=5)
                    mse_cv=mean_squared_error(y_train,y_pred_cv)
                    # r2_cv = r2_score(y_train, y_pred_cv)

                    
                    # Log metrics
                    mlflow.log_metrics({
                        "train_mse": mse_train,
                        "valid_mse": mse_valid,
                        "test_mse": mse_test,
                        # "train_r2": r2_train,
                        # "valid_r2": r2_valid,
                        # "test_r2": r2_test,
                        # "cv_r2": r2_cv,
                        "cv_mse":mse_cv
                    })
                    
                    # Display results
                    st.write("**ðŸŸ¢ Huáº¥n luyá»‡n mÃ´ hÃ¬nh**")
                    results_df = pd.DataFrame({
                        "Metric": ["MSE (Train)", "MSE (Validation)", "MSE (Test)", "MSE (Cross-Validation)"],
                        "Value": [mse_train, mse_valid, mse_test, mse_cv]
                    })

                    # Hiá»ƒn thá»‹ báº£ng trong Streamlit
                    st.write("### ðŸ“Š Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh")
                    st.table(results_df)
                    
        
        # Prediction interface
            st.subheader("Prediction Interface")
            # Kiá»ƒm tra náº¿u mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n trÆ°á»›c khi dá»± Ä‘oÃ¡n
            if 'model' in st.session_state:
                analyzer.model = st.session_state['model']
                analyzer.scaler = st.session_state['scaler']
                analyzer.poly = st.session_state['poly']
                analyzer.is_fitted = True
            else:
                st.error("Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c khi dá»± Ä‘oÃ¡n!")

            if analyzer.is_fitted:
                col1, col2 = st.columns(2)
            
                with col1:
                    pclass = st.selectbox("Passenger Class", [1, 2, 3])
                    age = st.number_input("Age", 0, 100, 30)
                    sex = st.selectbox("Sex", ["male", "female"])
                
                with col2:
                    sibsp = st.number_input("Siblings/Spouses", 0, 10, 0)
                    parch = st.number_input("Parents/Children", 0, 10, 0)
                    fare = st.number_input("Fare", 0.0, 500.0, 32.0)
                    embarked = st.selectbox("Port of Embarkation", ['C', 'Q', 'S'])
                
            if st.button("Predict"):
                # Create input DataFrame
                input_data = pd.DataFrame({
                    'Pclass': [pclass],
                    'Age': [age],
                    'SibSp': [sibsp],
                    'Parch': [parch],
                    'Fare': [fare],
                    'Sex': [1 if sex == 'female' else 0],
                    'Embarked_C': [1 if embarked == 'C' else 0],
                    'Embarked_Q': [1 if embarked == 'Q' else 0],
                    'Embarked_S': [1 if embarked == 'S' else 0]
                })
                
                # Make prediction
                survival_prediction = analyzer.predict_survival(input_data)
                
                if survival_prediction is not None:
                    st.success(f"Dá»± Ä‘oÃ¡n : {'Survived' if survival_prediction == 1 else 'Not Survived'}")

    with tab3:
        # Hiá»ƒn thá»‹ MLflow Tracking UI trong iframe
        mlflow_url = "http://localhost:5000"  # Thay Ä‘á»•i náº¿u cháº¡y trÃªn server khÃ¡c
        st.markdown(f'<iframe src="{mlflow_url}" width="800" height="400"></iframe>', unsafe_allow_html=True)

if __name__ == "__main__":
    create_streamlit_app()
