import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
import mlflow
import mlflow.sklearn
import streamlit as st
import plotly.express as px
from sklearn.metrics import mean_squared_error, r2_score
import os

class TitanicAnalyzer:
    def __init__(self):
        self.data = None
        self.model = None
        self.scaler = None  # S·∫Ω kh·ªüi t·∫°o sau khi c√≥ d·ªØ li·ªáu
        self.poly = None
        self.feature_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
        self.is_fitted = False
    
    def load_and_preprocess(self, data_path):
        """ƒê·ªçc v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v·ªõi MLflow"""
        try:
            mlflow.start_run()
            st.header("**üìöTi·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**")
            
            # ƒê·ªçc d·ªØ li·ªáu
            st.write("**1. ƒê·ªçc d·ªØ li·ªáu**")
            self.data = pd.read_csv(data_path)
            mlflow.log_param("initial_data_shape", self.data.shape)
            st.write("D·ªØ li·ªáu ban ƒë·∫ßu:", self.data.head())
            
            # X·ª≠ l√Ω missing values
            st.write("**2. X·ª≠ l√Ω gi√° tr·ªã b·ªã thi·∫øu**")
            st.write("\n- ƒêi·ªÅn gi√° tr·ªã thi·∫øu trong 'Age' b·∫±ng gi√° tr·ªã trung b√¨nh.\n- ƒêi·ªÅn gi√° tr·ªã thi·∫øu trong 'Embarked' b·∫±ng gi√° tr·ªã xu·∫•t hi·ªán nhi·ªÅu nh·∫•t.")
            missing_values_before = self.data.isnull().sum().sum()
            st.write("S·ªë l∆∞·ª£ng d·ªØ li·ªáu b·ªã thi·∫øu : ")
            st.write(self.data.isnull().sum().T)
            imputer = SimpleImputer(strategy='mean')
            self.data[self.feature_columns] = imputer.fit_transform(self.data[self.feature_columns])
            missing_values_after = self.data.isnull().sum().sum()
            mlflow.log_metric("missing_values_before", missing_values_before)
            mlflow.log_metric("missing_values_after", missing_values_after)
            st.write("D·ªØ li·ªáu sau khi x·ª≠ l√Ω :", self.data.head())

            # X√≥a c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt
            st.write("**3. X√≥a c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt: Cabin, Name, Ticket**")
            st.write("\n- X√≥a c·ªôt 'Name' (T√™n h√†nh kh√°ch kh√¥ng ·∫£nh h∆∞·ªõng tr·ª±c ti·∫øp ƒë·∫øn s·ªëng s√≥t hay kh√¥ng).\n- X√≥a c·ªôt 'Ticket' (S·ªë v√© l√† m·ªôt chu·ªói k√Ω t·ª± kh√¥ng mang nhi·ªÅu √Ω nghƒ©a r√µ r√†ng ƒë·ªëi v·ªõi m√¥ h√¨nh d·ª± ƒëo√°n).\n- X√≥a c·ªôt 'Cabin' (D·ªØ li·ªáu b·ªã thi·∫øu qu√° nhi·ªÅu ,r·∫•t nhi·ªÅu h√†nh kh√°ch kh√¥ng c√≥ th√¥ng tin v·ªÅ cabin).")
            self.data.drop(columns=['Cabin', 'Name', 'Ticket'], inplace=True, errors='ignore')
            mlflow.log_param("after_column_removal_shape", self.data.shape)
            st.write("D·ªØ li·ªáu sau khi x√≥a c·ªôt:", self.data.head())
            
            # Chuy·ªÉn ƒë·ªïi bi·∫øn categorical
            st.write("**4. Chuy·ªÉn ƒë·ªïi bi·∫øn ph√¢n lo·∫°i**")
            self.data['Sex'] = (self.data['Sex'] == 'female').astype(int)
            self.feature_columns.append('Sex')
            st.write("D·ªØ li·ªáu sau khi chuy·ªÉn ƒë·ªïi 'Sex': male:0 - female: 1 ", self.data[['Sex']].head())
            
            # One-hot encoding cho Embarked
            st.write("**5. One-hot encoding cho Embarked**")
            st.write("""One-Hot Encoding (M√£ h√≥a One-Hot) l√† m·ªôt ph∆∞∆°ng ph√°p chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu d·∫°ng ph√¢n lo·∫°i (categorical data) th√†nh d·∫°ng s·ªë ƒë·ªÉ s·ª≠ d·ª•ng trong c√°c m√¥ h√¨nh h·ªçc m√°y.
                Thay v√¨ g√°n nh√£n b·∫±ng s·ªë nguy√™n (v√≠ d·ª•: 0, 1, 2), One-Hot Encoding s·∫Ω t·∫°o ra c√°c c·ªôt nh·ªã ph√¢n (0 ho·∫∑c 1) cho t·ª´ng gi√° tr·ªã duy nh·∫•t trong c·ªôt ph√¢n lo·∫°i.""")

            st.image("d1.png")
            st.write("Thay v√¨ g√°n s·ªë nguy√™n (0,1,2) cho Embarked, ta t·∫°o ra 3 c·ªôt m·ªõi: Embarked_C, Embarked_Q, Embarked_S")
            embarked_dummies = pd.get_dummies(self.data['Embarked'], prefix='Embarked')
            self.data = pd.concat([self.data, embarked_dummies], axis=1)
            self.feature_columns.extend(embarked_dummies.columns)
            mlflow.log_param("one_hot_encoded_columns", list(embarked_dummies.columns))
            st.write("D·ªØ li·ªáu sau khi One-Hot Encoding cho 'Embarked':")
            st.write(self.data[embarked_dummies.columns].head())

            
            mlflow.end_run()
            return self.data
            
        except Exception as e:
            st.error(f"L·ªói khi ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: {str(e)}")
            mlflow.end_run(status='FAILED')
            return None

    def split_data(self, train_size=0.7, valid_size=0.15):
        """Chia d·ªØ li·ªáu th√†nh t·∫≠p train/valid/test v√† chu·∫©n h√≥a"""
        try:
            with mlflow.start_run(run_name="Data_Splitting"):
                
                st.header("**üìöChia d·ªØ li·ªáu th√†nh t·∫≠p train/valid/test**")
                
                test_size = 1 - train_size - valid_size
                st.write(f"üî∏ T·ªâ l·ªá: Train = {train_size}, Valid = {valid_size}, Test = {test_size}")
                
                X = self.data[self.feature_columns]
                y = self.data['Survived']
                
                # Split th√†nh train v√† temp
                st.write("**1. Chia d·ªØ li·ªáu th√†nh t·∫≠p train v√† temp**")
                X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train_size, random_state=42)
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p train: {X_train.shape}")
                
                # Split temp th√†nh valid v√† test
                valid_ratio = valid_size / (valid_size + test_size)
                st.write("**2. Chia t·∫≠p temp th√†nh t·∫≠p validation v√† test**")
                X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, train_size=valid_ratio, random_state=42)
                st.write(f"üî∏ K√≠ch th∆∞·ªõc t·∫≠p valid: {X_valid.shape}")
                st.write(f"üî∏ K√≠ch th∆∞·ªõc t·∫≠p test: {X_test.shape}")
                
                # Kh·ªüi t·∫°o v√† fit scaler v·ªõi training data
                st.write("**3. Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng StandardScaler**")
                st.write("StandardScaler chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng c√°ch ƒë∆∞a gi√° tr·ªã trung b√¨nh v·ªÅ 0 v√† ƒë·ªô l·ªách chu·∫©n v·ªÅ 1.")
                self.scaler = StandardScaler()
                X_train_scaled = self.scaler.fit_transform(X_train)
                X_valid_scaled = self.scaler.transform(X_valid)
                X_test_scaled = self.scaler.transform(X_test)
                
                st.write("üìä **D·ªØ li·ªáu sau khi chu·∫©n h√≥a (5 d√≤ng ƒë·∫ßu ti√™n):**")
                st.write(pd.DataFrame(X_train_scaled[:5], columns=self.feature_columns))
                
                self.is_fitted = True
                
                # Log th√¥ng tin v√†o MLflow
                mlflow.log_param("train_size", X_train.shape)
                mlflow.log_param("valid_size", X_valid.shape)
                mlflow.log_param("test_size", X_test.shape)
                mlflow.log_param("scaling_method", "StandardScaler")
                mlflow.end_run()
                
                return (X_train_scaled, X_valid_scaled, X_test_scaled, y_train, y_valid, y_test)
                        
        except Exception as e:
            mlflow.log_param("status", "FAILED")
            st.error(f"‚ùå L·ªói khi chia d·ªØ li·ªáu: {str(e)}")
            mlflow.end_run(status='FAILED')
            return None

    def predict_survival(self, input_data):
        """D·ª± ƒëo√°n cho d·ªØ li·ªáu m·ªõi"""
        try:
            if not self.is_fitted:
                raise Exception("Model is not fitted yet. Please train the model first.")
            
            # Scale input using fitted scaler
            input_scaled = self.scaler.transform(input_data[self.feature_columns])
            
            # Predict
            if self.poly is not None:
                input_poly = self.poly.transform(input_scaled)
                prediction = self.model.predict(input_poly)[0]
            else:
                prediction = self.model.predict(input_scaled)[0]
            
            return prediction
            
        except Exception as e:
            st.error(f"Error in prediction: {str(e)}")
            return None

def create_streamlit_app():
    st.title("Titanic üö¢")
    
    # S·ª≠ d·ª•ng st.tabs ƒë·ªÉ t·∫°o thanh menu
    tab2, tab3 = st.tabs([ "üîç Hu·∫•n luy·ªán v√† D·ª± ƒëo√°n", "üöÄ MLflow"])
    analyzer = TitanicAnalyzer()
        
    with tab2:

            data_path = "titanic.csv"  # ƒê∆∞·ªùng d·∫´n c·ªë ƒë·ªãnh
            analyzer = TitanicAnalyzer()
            data = analyzer.load_and_preprocess(data_path)
                    
            # Parameters
            st.sidebar.header("Training Parameters")
            train_size = st.sidebar.slider("Training Set Size", 0.5, 0.8, 0.7)
            valid_size = st.sidebar.slider("Validation Set Size", 0.1, 0.25, 0.15)
            degree = st.sidebar.selectbox("Polynomial Degree", [1, 2, 3])
            
                # Split data
            splits = analyzer.split_data(train_size, valid_size)
                
            if splits is not None:
                X_train, X_valid, X_test, y_train, y_valid, y_test = splits
                
                with mlflow.start_run():
                    # Train model
                    if degree > 1:
                        analyzer.poly = PolynomialFeatures(degree=degree)
                        X_train_poly = analyzer.poly.fit_transform(X_train)
                        X_valid_poly = analyzer.poly.transform(X_valid)
                        X_test_poly = analyzer.poly.transform(X_test)
                        
                        analyzer.model = LogisticRegression()
                        analyzer.model.fit(X_train_poly, y_train)
                        # D·ª± ƒëo√°n
                        y_pred_train = analyzer.model.predict(X_train_poly)
                        y_pred_valid = analyzer.model.predict(X_valid_poly)
                        y_pred_test = analyzer.model.predict(X_test_poly)
                    else:
                        analyzer.model = LogisticRegression()
                        analyzer.model.fit(X_train, y_train)
                    
                    # Luwu m√¥ h√¨nh v√†o session_state
                        st.session_state['model'] = analyzer.model
                        st.session_state['scaler'] = analyzer.scaler
                        st.session_state['poly'] = analyzer.poly
                    # D·ª± ƒëo√°n
                        y_pred_train = analyzer.model.predict(X_train)
                        y_pred_valid = analyzer.model.predict(X_valid)
                        y_pred_test = analyzer.model.predict(X_test)
                    
                    # Calculate metrics
                    
                    mse_train = mean_squared_error(y_train, y_pred_train)
                    r2_train = r2_score(y_train, y_pred_train)
                    mse_valid = mean_squared_error(y_valid, y_pred_valid)
                    r2_valid = r2_score(y_valid, y_pred_valid)
                    mse_test = mean_squared_error(y_test, y_pred_test)
                    r2_test = r2_score(y_test, y_pred_test)
                    
                    # Cross-validation
                    y_pred_cv = cross_val_predict(analyzer.model, X_train, y_train, cv=5)
                    mse_cv=mean_squared_error(y_train,y_pred_cv)
                    # r2_cv = r2_score(y_train, y_pred_cv)

                    
                    # Log metrics
                    mlflow.log_metrics({
                        "train_mse": mse_train,
                        "valid_mse": mse_valid,
                        "test_mse": mse_test,
                        # "train_r2": r2_train,
                        # "valid_r2": r2_valid,
                        # "test_r2": r2_test,
                        # "cv_r2": r2_cv,
                        "cv_mse":mse_cv
                    })
                    
                    # Display results
                    st.header("**üìä Hu·∫•n luy·ªán m√¥ h√¨nh**")
                    st.image("d3.jpg")
                    st.write("**. ƒê√°nh gi√° m√¥ h√¨nh**")
                    st.write("- MSE (Mean Squared Error) l√† Sai s·ªë b√¨nh ph∆∞∆°ng trung b√¨nh l√† m·ªôt ch·ªâ s·ªë ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh h·ªìi quy, ƒëo l∆∞·ªùng m·ª©c ƒë·ªô sai l·ªách gi·ªØa gi√° tr·ªã th·ª±c t·∫ø v√† gi√° tr·ªã d·ª± ƒëo√°n.")
                    st.write("C√¥ng th·ª©c c·ªßa MSE :")
                    st.image("d4.jpg")
                    st.write("- Cross Validation (CV) l√† m·ªôt k·ªπ thu·∫≠t trong Machine Learning gi√∫p ƒë√°nh gi√° m√¥ h√¨nh m·ªôt c√°ch ch√≠nh x√°c b·∫±ng c√°ch chia d·ªØ li·ªáu th√†nh nhi·ªÅu ph·∫ßn ƒë·ªÉ hu·∫•n luy·ªán v√† ki·ªÉm tra nhi·ªÅu l·∫ßn, thay v√¨ ch·ªâ d√πng m·ªôt t·∫≠p d·ªØ li·ªáu c·ªë ƒë·ªãnh.")
                    st.image("d2.jpg",width=400)
                    results_df = pd.DataFrame({
                        "Metric": ["MSE (Train)", "MSE (Validation)", "MSE (Test)", "MSE (Cross-Validation)"],
                        "Value": [mse_train, mse_valid, mse_test, mse_cv]
                    })

                    # Hi·ªÉn th·ªã b·∫£ng trong Streamlit
                    st.write("**K·∫øt qu·∫£ ƒë√°nh gi√° m√¥ h√¨nh**")
                    st.table(results_df)
                    
        
        # Prediction interface
            st.subheader("Giao di·ªán d·ª± ƒëo√°n")
            # Ki·ªÉm tra n·∫øu m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc khi d·ª± ƒëo√°n
            if 'model' in st.session_state:
                analyzer.model = st.session_state['model']
                analyzer.scaler = st.session_state['scaler']
                analyzer.poly = st.session_state['poly']
                analyzer.is_fitted = True
            else:
                st.error("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n!")

            if analyzer.is_fitted:
                col1, col2 = st.columns(2)
            
                with col1:
                    pclass = st.selectbox("Passenger Class", [1, 2, 3])
                    age = st.number_input("Age", 0, 100, 30)
                    sex = st.selectbox("Sex", ["male", "female"])
                
                with col2:
                    sibsp = st.number_input("Siblings/Spouses", 0, 10, 0)
                    parch = st.number_input("Parents/Children", 0, 10, 0)
                    fare = st.number_input("Fare", 0.0, 500.0, 32.0)
                    embarked = st.selectbox("Port of Embarkation", ['C', 'Q', 'S'])
                
            if st.button("Predict"):
                # Create input DataFrame
                input_data = pd.DataFrame({
                    'Pclass': [pclass],
                    'Age': [age],
                    'SibSp': [sibsp],
                    'Parch': [parch],
                    'Fare': [fare],
                    'Sex': [1 if sex == 'female' else 0],
                    'Embarked_C': [1 if embarked == 'C' else 0],
                    'Embarked_Q': [1 if embarked == 'Q' else 0],
                    'Embarked_S': [1 if embarked == 'S' else 0]
                })
                
                # Make prediction
                survival_prediction = analyzer.predict_survival(input_data)
                
                if survival_prediction is not None:
                    st.success(f"D·ª± ƒëo√°n : {'Survived' if survival_prediction == 1 else 'Not Survived'}")

    with tab3:
        # Hi·ªÉn th·ªã MLflow Tracking UI trong iframe
        mlflow_url = "http://localhost:5000"  # Thay ƒë·ªïi n·∫øu ch·∫°y tr√™n server kh√°c
        st.markdown(f'<iframe src="{mlflow_url}" width="800" height="400"></iframe>', unsafe_allow_html=True)

if __name__ == "__main__":
    create_streamlit_app()
