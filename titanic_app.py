import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.impute import SimpleImputer
import mlflow
import mlflow.sklearn
import streamlit as st
import plotly.express as px
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import os

class TitanicAnalyzer:
    def __init__(self):
        self.data = None
        self.model = None
        self.scaler = None  # S·∫Ω kh·ªüi t·∫°o sau khi c√≥ d·ªØ li·ªáu
        self.poly = None
        self.feature_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']
        self.is_fitted = False
    
    def load_and_preprocess(self, data_path):
        """ƒê·ªçc v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v·ªõi MLflow"""
        try:
            mlflow.start_run()
            st.write("**üü¢ Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu**")
            
            # ƒê·ªçc d·ªØ li·ªáu
            st.write("**1. ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV**")
            self.data = pd.read_csv(data_path)
            mlflow.log_param("initial_data_shape", self.data.shape)
            st.write("D·ªØ li·ªáu ban ƒë·∫ßu:", self.data.head())
            
            # X·ª≠ l√Ω missing values
            st.write("**2. X·ª≠ l√Ω gi√° tr·ªã b·ªã thi·∫øu b·∫±ng ph∆∞∆°ng ph√°p trung b√¨nh**")
            st.write("\n- ƒêi·ªÅn gi√° tr·ªã thi·∫øu trong 'Age' b·∫±ng gi√° tr·ªã trung b√¨nh.\n- ƒêi·ªÅn gi√° tr·ªã thi·∫øu trong 'Embarked' b·∫±ng gi√° tr·ªã xu·∫•t hi·ªán nhi·ªÅu nh·∫•t.")
            missing_values_before = self.data.isnull().sum().sum()
            st.write("S·ªë l∆∞·ª£ng d·ªØ li·ªáu b·ªã thi·∫øu : ")
            st.write(self.data.isnull().sum().T)
            imputer = SimpleImputer(strategy='mean')
            self.data[self.feature_columns] = imputer.fit_transform(self.data[self.feature_columns])
            missing_values_after = self.data.isnull().sum().sum()
            mlflow.log_metric("missing_values_before", missing_values_before)
            mlflow.log_metric("missing_values_after", missing_values_after)
            st.write("D·ªØ li·ªáu sau khi x·ª≠ l√Ω :", self.data.head())

            # X√≥a c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt
            st.write("**3. X√≥a c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt: Cabin, Name, Ticket**")
            st.write("\n- X√≥a c·ªôt 'Name' (T√™n h√†nh kh√°ch kh√¥ng ·∫£nh h∆∞·ªõng tr·ª±c ti·∫øp ƒë·∫øn s·ªëng s√≥t hay kh√¥ng).\n- X√≥a c·ªôt 'Ticket' (S·ªë v√© l√† m·ªôt chu·ªói k√Ω t·ª± kh√¥ng mang nhi·ªÅu √Ω nghƒ©a r√µ r√†ng ƒë·ªëi v·ªõi m√¥ h√¨nh d·ª± ƒëo√°n).\n- X√≥a c·ªôt 'Cabin' (D·ªØ li·ªáu b·ªã thi·∫øu qu√° nhi·ªÅu ,r·∫•t nhi·ªÅu h√†nh kh√°ch kh√¥ng c√≥ th√¥ng tin v·ªÅ cabin).")
            self.data.drop(columns=['Cabin', 'Name', 'Ticket'], inplace=True, errors='ignore')
            mlflow.log_param("after_column_removal_shape", self.data.shape)
            st.write("D·ªØ li·ªáu sau khi x√≥a c·ªôt:", self.data.head())
            
            # Chuy·ªÉn ƒë·ªïi bi·∫øn categorical
            st.write("**4. Chuy·ªÉn ƒë·ªïi bi·∫øn ph√¢n lo·∫°i**")
            self.data['Sex'] = (self.data['Sex'] == 'female').astype(int)
            self.feature_columns.append('Sex')
            st.write("D·ªØ li·ªáu sau khi chuy·ªÉn ƒë·ªïi 'Sex':", self.data[['Sex']].head())
            
            # One-hot encoding cho Embarked
            st.write("**5. One-hot encoding**")
            embarked_dummies = pd.get_dummies(self.data['Embarked'], prefix='Embarked')
            self.data = pd.concat([self.data, embarked_dummies], axis=1)
            self.feature_columns.extend(embarked_dummies.columns)
            mlflow.log_param("one_hot_encoded_columns", list(embarked_dummies.columns))
            st.write("D·ªØ li·ªáu sau khi one-hot encoding:", self.data.head())
            
            mlflow.end_run()
            return self.data
            
        except Exception as e:
            st.error(f"L·ªói khi ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu: {str(e)}")
            mlflow.end_run(status='FAILED')
            return None

    def split_data(self, train_size=0.7, valid_size=0.15):
        """Chia d·ªØ li·ªáu th√†nh t·∫≠p train/valid/test v√† chu·∫©n h√≥a"""
        try:
            with mlflow.start_run(run_name="Data_Splitting"):
                
                st.write("**üü¢ Chia d·ªØ li·ªáu th√†nh t·∫≠p train/valid/test**")
                
                test_size = 1 - train_size - valid_size
                st.write(f"üî∏ T·ªâ l·ªá: Train = {train_size}, Valid = {valid_size}, Test = {test_size}")
                
                X = self.data[self.feature_columns]
                y = self.data['Survived']
                
                # Split th√†nh train v√† temp
                st.write("**1. Chia d·ªØ li·ªáu th√†nh t·∫≠p train v√† t·∫≠p t·∫°m th·ªùi**")
                X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train_size, random_state=42)
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p train: {X_train.shape}")
                
                # Split temp th√†nh valid v√† test
                valid_ratio = valid_size / (valid_size + test_size)
                st.write("**2. Chia t·∫≠p t·∫°m th·ªùi th√†nh t·∫≠p validation v√† test**")
                X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, train_size=valid_ratio, random_state=42)
                st.write(f"üî∏ K√≠ch th∆∞·ªõc t·∫≠p valid: {X_valid.shape}")
                st.write(f"üî∏ K√≠ch th∆∞·ªõc t·∫≠p test: {X_test.shape}")
                
                # Kh·ªüi t·∫°o v√† fit scaler v·ªõi training data
                st.write("**3. Chu·∫©n h√≥a d·ªØ li·ªáu b·∫±ng StandardScaler**")
                self.scaler = StandardScaler()
                X_train_scaled = self.scaler.fit_transform(X_train)
                X_valid_scaled = self.scaler.transform(X_valid)
                X_test_scaled = self.scaler.transform(X_test)
                
                st.write("üìä **D·ªØ li·ªáu sau khi chu·∫©n h√≥a (5 d√≤ng ƒë·∫ßu ti√™n):**")
                st.write(pd.DataFrame(X_train_scaled[:5], columns=self.feature_columns))
                
                self.is_fitted = True
                
                # Log th√¥ng tin v√†o MLflow
                mlflow.log_param("train_size", X_train.shape)
                mlflow.log_param("valid_size", X_valid.shape)
                mlflow.log_param("test_size", X_test.shape)
                mlflow.log_param("scaling_method", "StandardScaler")
                mlflow.end_run()
                
                return (X_train_scaled, X_valid_scaled, X_test_scaled, y_train, y_valid, y_test)
                        
        except Exception as e:
            mlflow.log_param("status", "FAILED")
            st.error(f"‚ùå L·ªói khi chia d·ªØ li·ªáu: {str(e)}")
            mlflow.end_run(status='FAILED')
            return None

    def predict_survival(self, input_data):
        """D·ª± ƒëo√°n cho d·ªØ li·ªáu m·ªõi"""
        try:
            if not self.is_fitted:
                raise Exception("Model is not fitted yet. Please train the model first.")
            
            # Scale input using fitted scaler
            input_scaled = self.scaler.transform(input_data[self.feature_columns])
            
            # Predict
            if self.poly is not None:
                input_poly = self.poly.transform(input_scaled)
                prediction = self.model.predict(input_poly)[0]
            else:
                prediction = self.model.predict(input_scaled)[0]
            
            return prediction
            
        except Exception as e:
            st.error(f"Error in prediction: {str(e)}")
            return None

def create_streamlit_app():
    st.title("Titanic Survival Analysis")
    
    # S·ª≠ d·ª•ng st.tabs ƒë·ªÉ t·∫°o thanh menu
    tab2, tab3 = st.tabs([ "üîç Hu·∫•n luy·ªán v√† D·ª± ƒëo√°n", "üöÄ MLflow"])
    analyzer = TitanicAnalyzer()
        
    with tab2:
            st.header("D·ª± ƒëo√°n kh·∫£ nƒÉng s·ªëng s√≥t tr√™n t√†u Titanic")

            data_path = "G:/ML/MLFlow/my_env/titanic.csv"  # ƒê∆∞·ªùng d·∫´n c·ªë ƒë·ªãnh
            analyzer = TitanicAnalyzer()
            data = analyzer.load_and_preprocess(data_path)
                    
            # Parameters
            st.sidebar.header("Training Parameters")
            train_size = st.sidebar.slider("Training Set Size", 0.5, 0.8, 0.7)
            valid_size = st.sidebar.slider("Validation Set Size", 0.1, 0.25, 0.15)
            degree = st.sidebar.selectbox("Polynomial Degree", [1, 2, 3])
            
            st.write("Train Model")
                # Split data
            splits = analyzer.split_data(train_size, valid_size)
                
            if splits is not None:
                X_train, X_valid, X_test, y_train, y_valid, y_test = splits
                
                with mlflow.start_run():
                    # Train model
                    if degree > 1:
                        analyzer.poly = PolynomialFeatures(degree=degree)
                        X_train_poly = analyzer.poly.fit_transform(X_train)
                        X_valid_poly = analyzer.poly.transform(X_valid)
                        X_test_poly = analyzer.poly.transform(X_test)
                        
                        analyzer.model = LogisticRegression()
                        analyzer.model.fit(X_train_poly, y_train)
                        # D·ª± ƒëo√°n
                        y_pred_train = analyzer.model.predict(X_train_poly)
                        y_pred_valid = analyzer.model.predict(X_valid_poly)
                        y_pred_test = analyzer.model.predict(X_test_poly)
                    else:
                        analyzer.model = LogisticRegression()
                        analyzer.model.fit(X_train, y_train)
                    
                    # Luwu m√¥ h√¨nh v√†o session_state
                        st.session_state['model'] = analyzer.model
                        st.session_state['scaler'] = analyzer.scaler
                        st.session_state['poly'] = analyzer.poly
                    # D·ª± ƒëo√°n
                        y_pred_train = analyzer.model.predict(X_train)
                        y_pred_valid = analyzer.model.predict(X_valid)
                        y_pred_test = analyzer.model.predict(X_test)
                    
                    # Calculate metrics
                    train_accuracy = accuracy_score(y_train, y_pred_train)
                    valid_accuracy = accuracy_score(y_valid, y_pred_valid)
                    test_accuracy = accuracy_score(y_test, y_pred_test)
                    
                    # Cross-validation
                    cv_scores = cross_val_score(analyzer.model, X_train, y_train, cv=5)
                    cv_accuracy = np.mean(cv_scores)
                    
                    # Log metrics
                    mlflow.log_metrics({
                        "train_accuracy": train_accuracy,
                        "valid_accuracy": valid_accuracy,
                        "test_accuracy": test_accuracy,
                        "cv_accuracy": cv_accuracy
                    })
                    
                    # Display results
                    st.write("**üü¢ Hu·∫•n luy·ªán m√¥ h√¨nh**")
                    st.write("**K·∫øt qu·∫£ hu·∫•n luy·ªán**")
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("Train Accuracy", f"{train_accuracy:.4f}")
                    col2.metric("Validation Accuracy", f"{valid_accuracy:.4f}")
                    col3.metric("Test Accuracy", f"{test_accuracy:.4f}")
                    col4.metric("CV Accuracy", f"{cv_accuracy:.4f}")
                    
                    # Confusion matrix
                    st.write("**Confusion Matrix**")
                    conf_matrix = confusion_matrix(y_valid, y_pred_valid)
                    fig = px.imshow(conf_matrix, text_auto=True, labels=dict(x="Predicted", y="Actual"), x=['Not Survived', 'Survived'], y=['Not Survived', 'Survived'])
                    st.plotly_chart(fig)
                    
                    # Classification report
                    st.write("**Classification Report**")
                    report = classification_report(y_valid, y_pred_valid, output_dict=True)
                    st.table(pd.DataFrame(report).transpose())
        
        # Prediction interface
            st.subheader("Prediction Interface")
            # Ki·ªÉm tra n·∫øu m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán tr∆∞·ªõc khi d·ª± ƒëo√°n
            if 'model' in st.session_state:
                analyzer.model = st.session_state['model']
                analyzer.scaler = st.session_state['scaler']
                analyzer.poly = st.session_state['poly']
                analyzer.is_fitted = True
            else:
                st.error("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n!")

            if analyzer.is_fitted:
                col1, col2 = st.columns(2)
            
                with col1:
                    pclass = st.selectbox("Passenger Class", [1, 2, 3])
                    age = st.number_input("Age", 0, 100, 30)
                    sex = st.selectbox("Sex", ["male", "female"])
                
                with col2:
                    sibsp = st.number_input("Siblings/Spouses", 0, 10, 0)
                    parch = st.number_input("Parents/Children", 0, 10, 0)
                    fare = st.number_input("Fare", 0.0, 500.0, 32.0)
                    embarked = st.selectbox("Port of Embarkation", ['C', 'Q', 'S'])
                
            if st.button("Predict"):
                # Create input DataFrame
                input_data = pd.DataFrame({
                    'Pclass': [pclass],
                    'Age': [age],
                    'SibSp': [sibsp],
                    'Parch': [parch],
                    'Fare': [fare],
                    'Sex': [1 if sex == 'female' else 0],
                    'Embarked_C': [1 if embarked == 'C' else 0],
                    'Embarked_Q': [1 if embarked == 'Q' else 0],
                    'Embarked_S': [1 if embarked == 'S' else 0]
                })
                
                # Make prediction
                survival_prediction = analyzer.predict_survival(input_data)
                
                if survival_prediction is not None:
                    st.success(f"D·ª± ƒëo√°n : {'Survived' if survival_prediction == 1 else 'Not Survived'}")

    with tab3:
        # Hi·ªÉn th·ªã MLflow Tracking UI trong iframe
        mlflow_url = "http://localhost:5000"  # Thay ƒë·ªïi n·∫øu ch·∫°y tr√™n server kh√°c
        st.markdown(f'<iframe src="{mlflow_url}" width="800" height="400"></iframe>', unsafe_allow_html=True)

if __name__ == "__main__":
    create_streamlit_app()
